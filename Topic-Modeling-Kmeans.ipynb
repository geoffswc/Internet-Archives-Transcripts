{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "#pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = []\n",
    "\n",
    "for file in glob.glob(\"computer_transcripts/*.txt\"):\n",
    "\n",
    "    #print(file.split('/')[-1])\n",
    "    \n",
    "    with open(file,\"r\") as f:\n",
    "        text_content = f.read()\n",
    "        \n",
    "    file_contents.append((file, text_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcripts = pd.DataFrame(file_contents)\n",
    "df_transcripts.columns = ['file_name', 'text_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/8493czf93l34d7c5ky14j7pr0000gp/T/ipykernel_93506/1313516511.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_transcripts['alpha_text'] = df_transcripts.no_stop.str.replace(\"[^a-zA-Z]\", ' ')\n",
      "/var/folders/wp/8493czf93l34d7c5ky14j7pr0000gp/T/ipykernel_93506/1313516511.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_transcripts['alpha_text'] = df_transcripts['alpha_text'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "# data cleaning (stop words, remove non-alpha text, lemmatize)\n",
    "df_transcripts['no_stop'] = df_transcripts['text_content'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word.lower() not in stop))\n",
    "df_transcripts['alpha_text'] = df_transcripts.no_stop.str.replace(\"[^a-zA-Z]\", ' ')\n",
    "df_transcripts['alpha_text'] = df_transcripts['alpha_text'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "df_transcripts['no_stop'] = df_transcripts['alpha_text'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word.lower() not in stop))\n",
    "df_transcripts['lemmatized_text'] = df_transcripts['no_stop'].apply(\n",
    "    lambda words: ' '.join(lemmatizer.lemmatize(w) for w in words.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text = tfv.fit_transform(df_transcripts['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['file_name', 'text_content', 'no_stop', 'alpha_text',\n",
       "       'lemmatized_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcripts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "#words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up kmeans with 2 clusters, since we selected either advertising or legal\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(vec_text)\n",
    "cluster_words = kmeans.cluster_centers_\n",
    "df_cluster_words = pd.DataFrame(cluster_words, columns=words).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "filter         0.188225\n",
      "coupon         0.153383\n",
      "taste          0.116241\n",
      "raleigh        0.097545\n",
      "viceroy        0.090958\n",
      "gift           0.087537\n",
      "cigarette      0.074398\n",
      "flavor         0.069083\n",
      "gold           0.068982\n",
      "independent    0.067696\n",
      "extra          0.057755\n",
      "cool           0.055487\n",
      "smoke          0.053480\n",
      "better         0.051250\n",
      "fresh          0.051247\n",
      "time           0.049919\n",
      "right          0.049723\n",
      "king           0.045788\n",
      "never          0.045233\n",
      "bel            0.044509\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Cluster 1\n",
      "tobacco      0.132123\n",
      "would        0.126887\n",
      "think        0.119366\n",
      "question     0.104544\n",
      "morris       0.082012\n",
      "philip       0.081113\n",
      "cigarette    0.079573\n",
      "mr           0.078083\n",
      "company      0.076393\n",
      "case         0.076276\n",
      "nicotine     0.071952\n",
      "product      0.067135\n",
      "one          0.065102\n",
      "going        0.063498\n",
      "know         0.061543\n",
      "people       0.057811\n",
      "well         0.057203\n",
      "industry     0.056691\n",
      "year         0.055635\n",
      "time         0.055605\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most common words by cluster\n",
    "for i in range(0, 2):\n",
    "    print('Cluster', i)\n",
    "    print(df_cluster_words.sort_values(i, ascending=False)[i].head(20))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict a category for each document in the training set.\n",
    "# would be interesting to see how closely these match our categories of legal or advertising\n",
    "df_transcripts['pred'] = kmeans.predict(tfv.transform(df_transcripts['lemmatized_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer_transcripts/tobacco_qjb77c00.txt</td>\n",
       "      <td>good afternoon everybody thanks coming short n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer_transcripts/tobacco_kpr91e00.txt</td>\n",
       "      <td>living people think take independent action br...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer_transcripts/tobacco_qyq95i00.txt</td>\n",
       "      <td>going back record start take number two deposi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer_transcripts/tobacco_xpu03f00.txt</td>\n",
       "      <td>hardly folk never smoked raleigh cigarette wou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer_transcripts/tobacco_hno23e00.txt</td>\n",
       "      <td>good morning thank coming press conference nam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>computer_transcripts/tobacco_qdo23e00.txt</td>\n",
       "      <td>today cigarette cannot answer today smoking sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>computer_transcripts/tobacco_gav28d00.txt</td>\n",
       "      <td>hello welcome mark firestone vice president as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>computer_transcripts/tobacco_qar62a00.txt</td>\n",
       "      <td>name alberta think okay catch pas world end li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>computer_transcripts/tobacco_mnjp0149.txt</td>\n",
       "      <td>jonathan representing plane new york state act...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>computer_transcripts/tobacco_lpp06a00.txt</td>\n",
       "      <td>quota remained correct follow line questioning...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>computer_transcripts/tobacco_iwu03f00.txt</td>\n",
       "      <td>yeah come school make cool intro blanco lover ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>computer_transcripts/tobacco_lxkv0152.txt</td>\n",
       "      <td>back record beginning take two time approximat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>computer_transcripts/tobacco_gty99d00.txt</td>\n",
       "      <td>independent guy like set kind style care new c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>computer_transcripts/tobacco_ipu03f00.txt</td>\n",
       "      <td>hi ed hi joe yeah like hey really built kid im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>computer_transcripts/tobacco_ohq03d00.txt</td>\n",
       "      <td>breakthrough cigarette technology beginning mi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>computer_transcripts/tobacco_gxu03f00.txt</td>\n",
       "      <td>special treatment softens backhoe smoother mil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>computer_transcripts/tobacco_nou03f00.txt</td>\n",
       "      <td>hope twice refresh fight refresh belly fresh f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>computer_transcripts/tobacco_ich77e00.txt</td>\n",
       "      <td>rise barrier language geography dynamic brand ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>computer_transcripts/tobacco_kpp06a00.txt</td>\n",
       "      <td>wto cap hr contains comprehensive effective fd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>computer_transcripts/tobacco_jnjp0149.txt</td>\n",
       "      <td>back record beginning take two best fishing do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>computer_transcripts/tobacco_amp91f00.txt</td>\n",
       "      <td>think friend smoke become considerate people l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>computer_transcripts/tobacco_qmu03f00.txt</td>\n",
       "      <td>sorry son head seemed wood good place stay mou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>computer_transcripts/tobacco_kou03f00.txt</td>\n",
       "      <td>say something important filter tip smoker rale...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>computer_transcripts/tobacco_mpp06a00.txt</td>\n",
       "      <td>good morning hearing house committee agricultu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>computer_transcripts/tobacco_szy99d00.txt</td>\n",
       "      <td>sarah patron whose name mcnair barber trimming...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>computer_transcripts/tobacco_rdz99d00.txt</td>\n",
       "      <td>newport welcome place never hush never rough t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>computer_transcripts/tobacco_hxkv0152.txt</td>\n",
       "      <td>record jonathan chubb representing moron rosin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>computer_transcripts/tobacco_tpu03f00.txt</td>\n",
       "      <td>tackle aboard men around get underway viceroy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>computer_transcripts/tobacco_kkm09c00.txt</td>\n",
       "      <td>several hearing beginning march th mark bill g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>computer_transcripts/tobacco_ojq03d00.txt</td>\n",
       "      <td>pump foot stompin em jam pumpin looking crowd ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>computer_transcripts/tobacco_bbx27a00.txt</td>\n",
       "      <td>vineyard issue advertising whole issue public ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>computer_transcripts/tobacco_ziw99d00.txt</td>\n",
       "      <td>living people think get thinking must better w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>computer_transcripts/tobacco_lez99d00.txt</td>\n",
       "      <td>independent guy like set kind style care new c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>computer_transcripts/tobacco_byv27a00.txt</td>\n",
       "      <td>opening united state purchased exclusive use e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>computer_transcripts/tobacco_ldo23e00.txt</td>\n",
       "      <td>strike friendship new parliament parliament ci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file_name  \\\n",
       "0   computer_transcripts/tobacco_qjb77c00.txt   \n",
       "1   computer_transcripts/tobacco_kpr91e00.txt   \n",
       "2   computer_transcripts/tobacco_qyq95i00.txt   \n",
       "3   computer_transcripts/tobacco_xpu03f00.txt   \n",
       "4   computer_transcripts/tobacco_hno23e00.txt   \n",
       "5   computer_transcripts/tobacco_qdo23e00.txt   \n",
       "6   computer_transcripts/tobacco_gav28d00.txt   \n",
       "7   computer_transcripts/tobacco_qar62a00.txt   \n",
       "8   computer_transcripts/tobacco_mnjp0149.txt   \n",
       "9   computer_transcripts/tobacco_lpp06a00.txt   \n",
       "10  computer_transcripts/tobacco_iwu03f00.txt   \n",
       "11  computer_transcripts/tobacco_lxkv0152.txt   \n",
       "12  computer_transcripts/tobacco_gty99d00.txt   \n",
       "13  computer_transcripts/tobacco_ipu03f00.txt   \n",
       "14  computer_transcripts/tobacco_ohq03d00.txt   \n",
       "15  computer_transcripts/tobacco_gxu03f00.txt   \n",
       "16  computer_transcripts/tobacco_nou03f00.txt   \n",
       "17  computer_transcripts/tobacco_ich77e00.txt   \n",
       "18  computer_transcripts/tobacco_kpp06a00.txt   \n",
       "19  computer_transcripts/tobacco_jnjp0149.txt   \n",
       "20  computer_transcripts/tobacco_amp91f00.txt   \n",
       "21  computer_transcripts/tobacco_qmu03f00.txt   \n",
       "22  computer_transcripts/tobacco_kou03f00.txt   \n",
       "23  computer_transcripts/tobacco_mpp06a00.txt   \n",
       "24  computer_transcripts/tobacco_szy99d00.txt   \n",
       "25  computer_transcripts/tobacco_rdz99d00.txt   \n",
       "26  computer_transcripts/tobacco_hxkv0152.txt   \n",
       "27  computer_transcripts/tobacco_tpu03f00.txt   \n",
       "28  computer_transcripts/tobacco_kkm09c00.txt   \n",
       "29  computer_transcripts/tobacco_ojq03d00.txt   \n",
       "30  computer_transcripts/tobacco_bbx27a00.txt   \n",
       "31  computer_transcripts/tobacco_ziw99d00.txt   \n",
       "32  computer_transcripts/tobacco_lez99d00.txt   \n",
       "33  computer_transcripts/tobacco_byv27a00.txt   \n",
       "34  computer_transcripts/tobacco_ldo23e00.txt   \n",
       "\n",
       "                                      lemmatized_text  pred  \n",
       "0   good afternoon everybody thanks coming short n...     1  \n",
       "1   living people think take independent action br...     0  \n",
       "2   going back record start take number two deposi...     1  \n",
       "3   hardly folk never smoked raleigh cigarette wou...     0  \n",
       "4   good morning thank coming press conference nam...     1  \n",
       "5   today cigarette cannot answer today smoking sa...     0  \n",
       "6   hello welcome mark firestone vice president as...     1  \n",
       "7   name alberta think okay catch pas world end li...     0  \n",
       "8   jonathan representing plane new york state act...     1  \n",
       "9   quota remained correct follow line questioning...     1  \n",
       "10  yeah come school make cool intro blanco lover ...     0  \n",
       "11  back record beginning take two time approximat...     1  \n",
       "12  independent guy like set kind style care new c...     0  \n",
       "13  hi ed hi joe yeah like hey really built kid im...     0  \n",
       "14  breakthrough cigarette technology beginning mi...     1  \n",
       "15  special treatment softens backhoe smoother mil...     0  \n",
       "16  hope twice refresh fight refresh belly fresh f...     0  \n",
       "17  rise barrier language geography dynamic brand ...     1  \n",
       "18  wto cap hr contains comprehensive effective fd...     1  \n",
       "19  back record beginning take two best fishing do...     1  \n",
       "20  think friend smoke become considerate people l...     1  \n",
       "21  sorry son head seemed wood good place stay mou...     0  \n",
       "22  say something important filter tip smoker rale...     0  \n",
       "23  good morning hearing house committee agricultu...     1  \n",
       "24  sarah patron whose name mcnair barber trimming...     0  \n",
       "25  newport welcome place never hush never rough t...     0  \n",
       "26  record jonathan chubb representing moron rosin...     1  \n",
       "27  tackle aboard men around get underway viceroy ...     0  \n",
       "28  several hearing beginning march th mark bill g...     1  \n",
       "29  pump foot stompin em jam pumpin looking crowd ...     1  \n",
       "30  vineyard issue advertising whole issue public ...     1  \n",
       "31  living people think get thinking must better w...     0  \n",
       "32  independent guy like set kind style care new c...     0  \n",
       "33  opening united state purchased exclusive use e...     1  \n",
       "34  strike friendship new parliament parliament ci...     0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcripts[['file_name', 'lemmatized_text', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf \n",
    "pysqldf = lambda q: sqldf(q, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>COUNT(pred)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred  COUNT(pred)\n",
       "0     0           17\n",
       "1     1           18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifying records are evenly split between categories\n",
    "pysqldf(\"\"\"\n",
    "SELECT \n",
    "    pred, COUNT(pred)\n",
    "FROM\n",
    "    df_transcripts\n",
    "GROUP BY pred\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
